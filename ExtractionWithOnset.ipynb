{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os,IPython, librosa, mir_eval\n",
    "from sys import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join,isdir\n",
    "from IPython.display import Audio\n",
    "from librosa.display import waveplot,specshow\n",
    "from librosa.onset import onset_strength, onset_detect\n",
    "from librosa.feature import melspectrogram, mfcc\n",
    "from librosa import load\n",
    "\n",
    "from collections import defaultdict,OrderedDict\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import scipy\n",
    "from pandas import HDFStore,DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"Ubuntu\" in os.uname().version:\n",
    "    song, sampling_rate = librosa.load(\"/home/chib/Documents/fma_small/Electronic/99289.mp3\")\n",
    "\n",
    "#elif (comp == 'Lab'):\n",
    "#    song, sampling_rate = librosa.load(\"/Users/chibmac/Documents/fma_small/Electronic/99289.mp3\")\n",
    "\n",
    "else: \n",
    "    song, sampling_rate = librosa.load(librosa.util.example_audio_file())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660984"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_length = len(song)\n",
    "song_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,  36721,  73442, 110163, 146884, 183605, 220326, 257047,\n",
       "       293768, 330489, 367210, 403931, 440652, 477373, 514094, 550815,\n",
       "       587536, 624257, 660978])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of chunks to split the song into\n",
    "num_of_sections = 18\n",
    "\n",
    "#+1 so the last index is included, as python starts at 0\n",
    "song_splitter = np.arange(0,song_length+1,int(song_length/num_of_sections),dtype=int)\n",
    "song_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36721"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes each subset of a song (section) as its own song\n",
    "unit_song = song[song_splitter[0]:song_splitter[1]]\n",
    "unit_song_length = unit_song.shape[0]\n",
    "unit_song_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_of_mfcc = 12\n",
    "\n",
    "complete_split = num_of_sections *num_of_mfcc\n",
    "complete_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_width = np.int(unit_song_length/num_of_sections)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_mfcc = librosa.feature.mfcc(y=unit_song, sr=sampling_rate,n_mfcc=num_of_mfcc,hop_length = window_width).T\n",
    "\n",
    "unit_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36721,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_song.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2040)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_to_sect = int(unit_song_length/num_of_sections)\n",
    "unit_song= unit_song[:num_of_sections*song_to_sect]\n",
    "split_song = np.reshape(unit_song[:num_of_sections*song_to_sect],(num_of_sections,song_to_sect))\n",
    "split_song.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112,  54, 110, 204, 112, 128, 139, 104, 172, 156,  69, 112, 123,\n",
       "        66, 142, 174, 188, 132])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_zcr = np.sum(librosa.core.zero_crossings(split_song),axis =1)\n",
    "unit_zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_zcr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_unit_features=np.concatenate((unit_mfcc,np.array([unit_zcr]).T),axis=1)\n",
    "ind_unit_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def complete_extract_features(song,num_of_sections,num_of_mfcc,genre):  \n",
    "    complete_split = num_of_sections *num_of_mfcc        \n",
    "    song_splitter = np.arange(0,song_length+1,song_length/num_of_sections,dtype=int)\n",
    "    genres = np.ones(num_of_sections,dtype=int) * genre\n",
    "    onset_frames = librosa.onset.onset_detect(y=song, sr=sampling_rate)\n",
    "    for i in range(len(song_splitter)):\n",
    "        unit_song = song[song_splitter[i]:song_splitter[i+1]]\n",
    "        unit_song_length = unit_song.shape[0]\n",
    "        window_width = np.int(unit_song_length/num_of_sections)+1\n",
    "        #unit_mfcc = librosa.feature.mfcc(y=unit_song, sr=sampling_rate,n_mfcc=num_of_mfcc,hop_length = window_width).T\n",
    "        \n",
    "        split = int(len(unit_song)/num_of_sections)*num_of_sections\n",
    "        unit_song= unit_song[:split]\n",
    "    \n",
    "        split_song = np.reshape(unit_song,(num_of_sections,int(unit_song_length/num_of_sections)))\n",
    "        unit_zcr = np.sum(librosa.core.zero_crossings(split_song),axis =1)\n",
    "        #ind_unit_features=np.concatenate((unit_mfcc,np.array([unit_zcr]).T),axis=1)\n",
    "        ind_unit_features=np.array([unit_zcr]).T\n",
    "        ind_unit_features = np.reshape(ind_unit_features,(1,np.size(ind_unit_features)))\n",
    "               \n",
    "        genre = np.matrix(genre)\n",
    "        \n",
    "        #rep_genre =np.array([np.ones(num_of_sections,dtype=int)* 24]).T \n",
    "        onset_frames = np.matrix(librosa.onset.onset_detect(y=unit_song, sr=sampling_rate))\n",
    "        print(onset_frames.shape)\n",
    "        print(genre.shape)\n",
    "        print(num_of_sections)\n",
    "        print(ind_unit_features.shape)\n",
    "        temp = np.concatenate((ind_unit_features,onset_frames),axis=1)\n",
    "\n",
    "        #print(full_feat_gen)\n",
    "        \n",
    "        cent = np.matrix(librosa.feature.spectral_centroid(y=unit_song, sr=sampling_rate, hop_length= window_width)[0]).mean(axis =1)\n",
    "        print(cent.shape)\n",
    "        temp = np.concatenate((temp,cent),axis = 1).T\n",
    "        oenv = librosa.onset.onset_strength(y=unit_song, sr=sampling_rate, hop_length=window_width)\n",
    "        tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sampling_rate,\n",
    "                                      hop_length=window_width)\n",
    "        print (\"ok\",temp.shape)\n",
    "        print(tempogram.shape)\n",
    "        temp = np.concatenate((temp,tempogram.mean(axis = 1)),axis = 1)\n",
    "        full_feat_gen = np.concatenate((temp,genre),axis=1)\n",
    "        #print(tempogram.shape)\n",
    "        return cent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 18)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oenv = librosa.onset.onset_strength(y=unit_song, sr=sampling_rate, hop_length=window_width)\n",
    "tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sampling_rate,\n",
    "                              hop_length=window_width)\n",
    "\n",
    "tempogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  2.5,  4.5,  6.5,  8.5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10).reshape(5,2).mean(axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n",
      "(1, 1)\n",
      "18\n",
      "(1, 18)\n",
      "(1, 1)\n",
      "ok (31, 1)\n",
      "(384, 18)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-5e02b172e512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_sections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_mfcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-33034f2e10ee>\u001b[0m in \u001b[0;36mcomplete_extract_features\u001b[0;34m(song, num_of_sections, num_of_mfcc, genre)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtempogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mfull_feat_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#print(tempogram.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "test_out = complete_extract_features(song,num_of_sections,num_of_mfcc,10)\n",
    "\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Extraction from fma_small\n",
    "\n",
    "1. Find the song folder path relative to the current computer\n",
    "2. Retrieve the different genre classifications\n",
    "3. Identify each song via its full path to song using index, to guarantee one-to-one mapping \n",
    "4. Sort in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#retrieving path to the fma_small directory and the corresponding meta data\n",
    "HOME_DIR = IPython.utils.path.get_home_dir()\n",
    "\n",
    "temp = join(HOME_DIR, 'Documents')\n",
    "path_to_small_fma = join(temp, 'fma_small')\n",
    "json_file = join(path_to_small_fma,'fma_small.json')\n",
    "#locate meta_dta\n",
    "print(path_to_small_fma)\n",
    "df = pd.read_json(json_file)\n",
    "print(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only choose top genre as the label\n",
    "df = df.loc[:,['top_genre']]\n",
    "\n",
    "#ensure that the genre name matches file name in fma_small, \n",
    "#i.e Oldtime / Historian conflict issue\n",
    "df['top_genre']=df['top_genre'].apply(lambda y: y.split(os.sep)[0].strip())\n",
    "#locate each individual song by its full path\n",
    "df['temp'] = path_to_small_fma\n",
    "str_index = [\"%.2d\" % x for x in df.index]\n",
    "complete_genre_list = df['top_genre'].unique()\n",
    "\n",
    "#create full path to file and store as a single array\n",
    "df['full_path_to_song'] = df.temp.map(str)+ \"/\"+ df['top_genre'].values+ \"/\"+ str_index+ \".mp3\"\n",
    "del df['temp']\n",
    "#keep songs according to alphabetical order of songs \n",
    "df.sort_values(by = 'top_genre', inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_genre_list_df = pd.DataFrame(complete_genre_list, columns = ['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#retrieve number of songs per genre\n",
    "genre_and_count = df['top_genre'].value_counts().sort_index()\n",
    "all_songs_path = df['full_path_to_song'].values  \n",
    "print(genre_and_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_counts = [] \n",
    "ordered_genres = [] \n",
    "full_song_df = OrderedDict()\n",
    "genre_to_song_dict = {}\n",
    "\n",
    "\n",
    "#retrieve number of songs per genre with the order preserved in two lists\n",
    "#ordered_genres\n",
    "#song_counts\n",
    "for i,genre in enumerate(genre_and_count.index):\n",
    "    ordered_genres.append(genre)\n",
    "    temp = df['top_genre'].value_counts()[genre]\n",
    "    song_counts.append(temp)\n",
    "\n",
    "genre_to_song_zipped = zip(ordered_genres,song_counts)\n",
    "\n",
    "num_of_genre = np.shape(genre_and_count)[0]\n",
    "print(\"The number of genres is:\", num_of_genre)\n",
    "\n",
    "#dictionary with each song count and its corresponding genre\n",
    "for genre,song_count in genre_to_song_zipped:\n",
    "    genre_to_song_dict[genre] = song_count\n",
    "\n",
    "genre_to_song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_of_genre = np.shape(genre_and_count)[0]\n",
    "all_songs_path = df['full_path_to_song'].values\n",
    "\n",
    "paths_dict = OrderedDict()\n",
    "\n",
    "#prepend zero so we have a start point for all_songs_path \n",
    "#and avoid messing with indices\n",
    "\n",
    "#use the cumulative sum to find none uniform ranges\n",
    "song_counts.insert(0,0)\n",
    "cumulative_sum = np.cumsum(song_counts,dtype=int)\n",
    "\n",
    "#creates a dictionary of the genres and its corresponding path\n",
    "for i,genre in enumerate(ordered_genres):\n",
    "    str1=genre\n",
    "    str2 = \"_paths\"\n",
    "    genre_paths = \"\".join((str1,str2))\n",
    "    paths_dict[genre_paths] = all_songs_path[cumulative_sum[i]:cumulative_sum[i+1]]\n",
    "\n",
    "#paths_dict\n",
    "#{genre_path_name: genre_paths}\n",
    "print(\"{'Electronic_paths:[array_of_all_electronic_paths]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_of_songs = 3\n",
    "sampling_rate = 44100\n",
    "\n",
    "genre_signals_dict = OrderedDict()\n",
    "#creates a dictionary of the signals in a genre and their raw file\n",
    "for genre_path_name,genre_paths in paths_dict.items():\n",
    "    str1=genre_path_name[:-5]\n",
    "    str2 = \"signals\"\n",
    "    genre_signals = \"\".join((str1,str2))       \n",
    "    try:\n",
    "        first_three = genre_paths[:num_of_songs]\n",
    "        genre_signals_dict[genre_signals] = [\n",
    "        load(p,sr=None)[0] for p in first_three]\n",
    "    except IOError as exc:\n",
    "        print(\"Unable to locate folder\")\n",
    "        #raise IOError(\"%s: %s\" % (genre_paths, exc.strerror))\n",
    "        \n",
    "#genre_signals_dict\n",
    "#{genre_signals_name:genre_signals_paths}\n",
    "print(\"{'Electronic_signals:[array_of_all_electronic_paths]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the time series for each song according to the genres\n",
    "\n",
    "#sig_lengths = []\n",
    "for genre_signal_name,genre_signals in genre_signals_dict.items(): \n",
    "    for i, sig_amp in enumerate(genre_signals):\n",
    "        plt.subplot(1, num_of_songs, i+1)\n",
    "#        sig_lengths.append(len(sig_amp))\n",
    "        waveplot(sig_amp)\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.title(genre_signal_name)\n",
    "    plt.figure()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_num = 0\n",
    "tot_num_of_songs = cumulative_sum[-1]\n",
    "indiv_song_path= []\n",
    "for genre_path_name,genre_paths in paths_dict.items(): \n",
    "    song_num=song_num+1\n",
    "    indiv_song_path.append(genre_paths)\n",
    "  \n",
    "\n",
    "indiv_song_path_list = np.array(indiv_song_path).reshape(tot_num_of_songs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indiv_song_path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres = []\n",
    "for song_num in range(len(indiv_song_path_list)):\n",
    "    temp = indiv_song_path_list[song_num].split(os.sep)[-2]\n",
    "    genres.append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_genres= le.fit(genres)\n",
    "encoded_genres\n",
    "\n",
    "#Label Encoding Mapping\n",
    "encoder_df= pd.DataFrame(data= {'Genre':genres,\n",
    "                   'Encoded_Genre':le.transform(genres)})\n",
    "encoder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"I AM HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tot_num_of_songs = cumulative_sum[-1]\n",
    "final_d = np.zeros((tot_num_of_songs,test_out.shape[1]))\n",
    "print(final_d.shape)\n",
    "\n",
    "for song_num in range(len(indiv_song_path_list)):\n",
    "    try:\n",
    "        indiv_song_path = indiv_song_path_list[song_num]\n",
    "        song_signal = librosa.load(indiv_song_path,sr=None)[0]\n",
    "        curr_song_genre = encoder_df['Encoded_Genre'][song_num]\n",
    "        final_d[song_num]= complete_extract_features(song_signal,num_of_sections,num_of_mfcc,curr_song_genre)\n",
    "\n",
    "    except IOError as exc:\n",
    "        print(\"Unable to locate folder\")\n",
    "    \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"I AM HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "complete_df = pd.DataFrame(data=final_d.T,index =range(final_d.shape[1]))\n",
    "complete_df = complete_df.T\n",
    "\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([complete_df,encoder_df],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([complete_df,encoder_df],axis =1)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(\"complete_extract_with_onset.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
