{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Information Retrieval Based On The Free Music Archive Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,IPython\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from librosa.display import waveplot,specshow\n",
    "from librosa.onset import onset_strength, onset_detect\n",
    "from librosa.feature import melspectrogram, mfcc\n",
    "from librosa import load\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from librosa import load\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Extraction from fma_small\n",
    "\n",
    "1. Find the song folder path relative to the current computer\n",
    "2. Identify each song via its full path to song using index, to guarantee one-to-one mapping and Retrieve the different genre classifications.\n",
    "3. Sort in alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. This uses the Python Operating System (OS) library to access the file system that is unique to each OS .This enables to the code to be reused without modifying for individual computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chibmac/Documents/fma_small\n",
      "/Users/chibmac/Documents/fma_small/fma_small.json\n"
     ]
    }
   ],
   "source": [
    "#retrieving path to the fma_small directory and the corresponding meta data\n",
    "HOME_DIR = IPython.utils.path.get_home_dir()\n",
    "temp = join(HOME_DIR, 'Documents')\n",
    "path_to_small_fma = join(temp, 'fma_small')\n",
    "\n",
    "#locate meta_data\n",
    "json_file = join(path_to_small_fma,'fma_small.json')\n",
    "print(path_to_small_fma)\n",
    "df = pd.read_json(json_file)\n",
    "print(json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The genres and the train/test split are stored in the the json meta data associated with the cleaned FMA dataset from the LTS2 lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_genre</th>\n",
       "      <th>train</th>\n",
       "      <th>full_path_to_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100538</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43206</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43153</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43124</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43078</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42991</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42750</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>False</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16160</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42749</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>False</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42051</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42026</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41553</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/chibmac/Documents/fma_small/Electronic/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_genre  train                                  full_path_to_song\n",
       "100538  Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "43206   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "43199   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "43153   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "43124   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "43078   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "42991   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "42750   Electronic  False  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "16160   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "42749   Electronic  False  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "42051   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "42026   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/...\n",
       "41553   Electronic   True  /Users/chibmac/Documents/fma_small/Electronic/..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only choose top genre as the label\n",
    "df = df.loc[:,['top_genre','train']]\n",
    "\n",
    "#ensure that the genre name matches file name in fma_small, \n",
    "#i.e Oldtime / Historian conflict issue\n",
    "df['top_genre']=df['top_genre'].apply(lambda y: y.split(os.sep)[0].strip())\n",
    "#locate each individual song by its full path\n",
    "df['temp'] = path_to_small_fma\n",
    "str_index = [\"%.2d\" % x for x in df.index]\n",
    "\n",
    "complete_genre_list_df = pd.DataFrame(df['top_genre'].unique(), columns = ['Genre'])\n",
    "\n",
    "#create full path to file and store as a single array\n",
    "df['full_path_to_song'] = df.temp.map(str)+ \"/\"+ df['top_genre'].values+ \"/\"+ str_index+ \".mp3\"\n",
    "del df['temp']\n",
    "#keep songs according to alphabetical order of songs \n",
    "df.sort_values(by = 'top_genre', inplace = True)\n",
    "df.head(13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "num_of_songs = 3\n",
    "num_of_mfcc = 12\n",
    "sampling_rate = 44100\n",
    "min_song_length = 1322496\n",
    "num_of_songs = df.values.shape[0]\n",
    "num_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 564 ms, total: 17.9 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "complete_ds = np.zeros((10,3))\n",
    "\n",
    "for i in range(10):\n",
    "    curr_song = load(df['full_path_to_song'].values[i],sr = sampling_rate)[0][:min_song_length]\n",
    "    curr_genre = df['top_genre'].values[i]\n",
    "    curr_train = df['train'].values[i]\n",
    "    mfcc_per_segment = mfcc(y=curr_song, sr=sampling_rate,\n",
    "                                         n_mfcc=num_of_mfcc).T\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2584, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_per_segment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_extract_features(song,num_of_mfcces,genre,train):\n",
    "    #print(\"i am here\",song.shape)\n",
    "    try:\n",
    "        min_song_length = 1322496\n",
    "        short_song_length = int(min_song_length/2)\n",
    "        short_song_length = short_song_length-(short_song_length%2048)\n",
    "        #print(\"over here again\")\n",
    "        print(\"I got in\")\n",
    "        num_of_frames = int(short_song_length/2048)\n",
    "        #number of frames to nearest 10 \n",
    "        num_of_frames = num_of_frames-(num_of_frames%10)\n",
    "        \n",
    "        #the number of frames will always be a factor of 2048 and in addition 5,10 since it ends is rounded to nearest 10\n",
    "        segments_list = [1,2,4,5,8,10]\n",
    "        num_of_segments = segments_list[-1]\n",
    "        \n",
    "        num_of_frames_per_segment = int(num_of_frames/num_of_segments)\n",
    "        \n",
    "        shortest_song_length = num_of_frames *2048\n",
    "        \n",
    "        num_of_subframes = int(np.floor((shortest_song_length*4)/2048))\n",
    "        #num_of_frames = num_of_frames-(num_of_frames%10)\n",
    "        num_of_subframes_per_segment = int(num_of_subframes/num_of_segments)\n",
    "\n",
    "        print(\"I got in\")\n",
    "        song_f = song[:shortest_song_length -1] \n",
    "        song_t = song[:shortest_song_length] \n",
    "        ind_song_into_segment = int(len(song_t)/num_of_segments)\n",
    "        song_into_segments = np.reshape(song_t,(num_of_segments,ind_song_into_segment))\n",
    "\n",
    "        \n",
    "        zcr_features_per_segment = np.sum(librosa.core.zero_crossings(song_into_segments),axis = 1) #zero crossings returns boolean values\n",
    "        zcr_features_per_segment = np.reshape(zcr_features_per_segment,(zcr_features_per_segment.shape[0],1))\n",
    "        print(\"I got in\")\n",
    "        onset_frames = librosa.onset.onset_detect(y=song_t, sr=sampling_rate, units='samples')\n",
    "        onset_length = len(onset_frames)\n",
    "        song_splitter = np.arange(0,len(song_t)+1, ind_song_into_segment,dtype=int)\n",
    "        split_length = len(song_splitter)\n",
    "        total_onsets = [0]\n",
    "        \n",
    "        print(\"I got in\")\n",
    "        for i in range(1,len(song_splitter)):\n",
    "            total_onsets.append(np.sum(onset_frames<song_splitter[i]))\n",
    "\n",
    "        total_onset_diff = np.diff(total_onsets)\n",
    "        onsets_features_per_segment = np.reshape(total_onset_diff,(len(total_onset_diff),1))\n",
    "        time_domain_features = np.concatenate((zcr_features_per_segment,onsets_features_per_segment),axis =1)\n",
    "\n",
    "        #print(\"over here again1\")\n",
    "        mfcc_per_segment = librosa.feature.mfcc(y=song_f, sr=sampling_rate,\n",
    "                                         n_mfcc=num_of_mfcc).T\n",
    "        mfcc_per_segment = np.reshape(mfcc_per_segment,(num_of_segments,num_of_subframes_per_segment,num_of_mfcc))\n",
    "\n",
    "        mean_mfcc_per_segment = np.mean(mfcc_per_segment,axis=1)\n",
    "        var_mfcc_per_segment = np.var(mfcc_per_segment,axis =1)\n",
    "        skew_mfcc_per_segment = scipy.stats.skew(mfcc_per_segment,axis =1)\n",
    "        kurtosis_mfcc_per_segment = scipy.stats.kurtosis(mfcc_per_segment,axis =1)\n",
    "        #print(\"over here again2\")\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=song_f, sr=sampling_rate).T\n",
    "        spc_per_segment = np.reshape(spectral_centroid, (num_of_segments,num_of_subframes_per_segment))\n",
    "\n",
    "        mean_spc_per_segment = np.mean(spc_per_segment,axis=1)\n",
    "        mean_spc_per_segment = np.reshape(mean_spc_per_segment,(len(mean_spc_per_segment),1))\n",
    "        var_spc_per_segment = np.var(spc_per_segment,axis =1)\n",
    "        var_spc_per_segment = np.reshape(var_spc_per_segment,(len(var_spc_per_segment),1))\n",
    "        skew_spc_per_segment = scipy.stats.skew(spc_per_segment,axis =1)\n",
    "        skew_spc_per_segment = np.reshape(skew_spc_per_segment,(len(skew_spc_per_segment),1))\n",
    "        kurtosis_spc_per_segment = scipy.stats.kurtosis(spc_per_segment,axis =1)\n",
    "        kurtosis_spc_per_segment = np.reshape(kurtosis_spc_per_segment,(len(kurtosis_spc_per_segment),1))\n",
    "\n",
    "        spc_features_per_segment = np.concatenate((mean_spc_per_segment,var_spc_per_segment,skew_spc_per_segment,kurtosis_spc_per_segment),axis = 1)\n",
    "        #print(\"over here again3\")\n",
    "        freq_domain_feat_per_segment = np.concatenate((mfcc_features_per_segment,spc_features_per_segment),axis =1)\n",
    "        \n",
    "        features_per_segment= np.concatenate((time_domain_features,freq_domain_feat_per_segment),axis =1)\n",
    "        \n",
    "        #fps_x,fps_y = features_per_segment.shape\n",
    "        #features_per_segment = np.reshape(features_per_segment,(1,fps_x*fps_y))\n",
    "\n",
    "    except:        \n",
    "        print(\"There was an error whilst computing the features\")\n",
    "    return features_per_segment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The number of genres is:\", len(df['top_genre'].value_counts().sort_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "genres= np.repeat(df['top_genre'].values,10,axis=0)\n",
    "print(genres.shape)\n",
    "encoded_genres= le.fit(genres)\n",
    "train_labels = np.repeat(np.squeeze(df.loc[:,['train']].values), 10,axis = 0)\n",
    "print(train_labels.shape)\n",
    "encoded_genres\n",
    "\n",
    "#Label Encoding Mapping\n",
    "encoder_df= pd.DataFrame(data= {'Genre':genres,\n",
    "                   'Encoded_Genre':le.transform(genres),\n",
    "                               'Train': train_labels})\n",
    "encoder_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_of_songs = 3\n",
    "sampling_rate = 44100\n",
    "\n",
    "genre_signals_dict = OrderedDict()\n",
    "#creates a dictionary of the signals in a genre and their raw file\n",
    "for genre_path_name,genre_paths in paths_dict.items():\n",
    "    str1=genre_path_name[:-5]\n",
    "    str2 = \"signals\"\n",
    "    genre_signals = \"\".join((str1,str2))       \n",
    "    try:\n",
    "        first_three = genre_paths[:num_of_songs]\n",
    "        genre_signals_dict[genre_signals] = [\n",
    "        load(p,sr=None)[0] for p in first_three]\n",
    "    except IOError as exc:\n",
    "        print(\"Unable to locate folder\")\n",
    "        #raise IOError(\"%s: %s\" % (genre_paths, exc.strerror))\n",
    "        \n",
    "#genre_signals_dict\n",
    "#{genre_signals_name:genre_signals_paths}\n",
    "print(\"{'Electronic_signals:[array_of_all_electronic_paths]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_counts = [] \n",
    "ordered_genres = [] \n",
    "full_song_df = OrderedDict()\n",
    "genre_to_song_dict = {}\n",
    "\n",
    "#retrieve number of songs per genre\n",
    "genre_and_count = df['top_genre'].value_counts().sort_index()\n",
    "all_songs_path = df['full_path_to_song'].values  \n",
    "\n",
    "\n",
    "#retrieve number of songs per genre with the order preserved in two lists\n",
    "#ordered_genres\n",
    "#song_counts\n",
    "for i,genre in enumerate(genre_and_count.index):\n",
    "    ordered_genres.append(genre)\n",
    "    temp = df['top_genre'].value_counts()[genre]\n",
    "    song_counts.append(temp)\n",
    "\n",
    "genre_to_song_zipped = zip(ordered_genres,song_counts)\n",
    "\n",
    "num_of_genre = np.shape(genre_and_count)[0]\n",
    "print(\"The number of genres is:\", num_of_genre)\n",
    "\n",
    "#dictionary with each song count and its corresponding genre\n",
    "for genre,song_count in genre_to_song_zipped:\n",
    "    genre_to_song_dict[genre] = song_count\n",
    "\n",
    "genre_to_song_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song1, sampling_rate1 = load(\"/Users/chibmac/Documents/fma_small/Electronic/43206.mp3\")\n",
    "song2, sampling_rate2 = load(\"/Users/chibmac/Documents/fma_small/Electronic/43124.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_to_song_zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
